// The generated lexer module will start with this code
{
module FM4FUNLexer
open FSharp.Text.Lexing
open System
// open the module that defines the tokens
open FM4FUNParser
// Set the language to English such that 4.0 is parsed as 4 and not 40.
System.Globalization.CultureInfo.CurrentCulture <- new System.Globalization.CultureInfo("en-US")
}

// We define macros for some regular expressions we will use later
let digit       = ['0'-'9']
let char        = ['a'-'z' 'A'-'Z']
let num         = digit+ ( '.' digit+)?  ('E' ('+'|'-')? digit+ )?
let whitespace  = [' ' '\t']
let newline     = "\n\r" | '\n' | '\r'
let var        = char(char|digit)*



// We define now the rules for recognising and building tokens
// for each of the tokens of our language we need a rule
// NOTE: rules are applied in order top-down.
//       This is important when tokens overlap (not in this example)
rule tokenize = parse
// deal with tokens that need to be ignored (skip them)
| whitespace    { tokenize lexbuf }
| newline       { lexbuf.EndPos <- lexbuf.EndPos.NextLine; tokenize lexbuf; }
// deal with tokens that need to be built
| num           { NUM(Double.Parse(LexBuffer<_>.LexemeString lexbuf)) }
| "->"          {ARROW}
| '*'           { TIMES }
| '/'           { DIV }
| '+'           { PLUS }
| '-'           { MINUS }
| '^'           { POW }
| '('           { LPAR }
| ')'           { RPAR }
|'['            {LBRAC}
|']'            {RBRAC}
|"true"         {TRUE}
|"false"        {FALSE}
|'&'            {AND}
|'|'            {OR}
|"&&"           {ANDAND}
|"||"           {OROR}
|'!'            {NOT}
|"!="           {NOTEQUAL}
|">="           {GREATEREQUAL}
|'>'            {GREATER}
|"<="           {LESSEQUAL}
|'<'            {LESS}
|":="           {ASSIGN}
|'='            {EQUAL}
|"Skip"         {SKIP}
|';'            {SEMICOL}
|"if"           {IF}
|"fi"           {FI}
|"do"           {DO}
|"od"           {OD}
| var           { let str = LexBuffer<_>.LexemeString lexbuf in VAR(str) }
| eof           { EOF }


